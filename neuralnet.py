#!/bin/env python3
# coding: utf-8

import random
import numpy as np

def sigmoid(z):
    """
    Функция сигмоиды, которая на вход может принимать вектор из значений и
    выдавать на выходе вектор из посчитанных значений (т.е. сигмоида высчитывается
    для каждого элемента входного вектора)
    """
    return 1.0/(1.0+np.exp(-z))

def sigmoid_prime(z):
    """
    Производная сигмоиды σ(x) = 1 / (1 + e^(-x)):
    σ'(x) = σ(x) * (1 - σ(x))
    """
    return sigmoid(z)*(1-sigmoid(z))

"""
Этот класс, реализующий простую нейросеть.
После создания объекта класса:
>>> net = network.Network([784, 30, 10])
Импортируем данные для тренировки и тестирования сети, например, данные MNIST'a:
>>> import mnist_data.mnist_loader
>>> training_data, validation_data, test_data = mnist_loader.load_data_wrapper()
Далее вызываем главный метод, который запускает движуху:
>>> net.SGD(training_data, 30, 10, 3.0, test_data=test_data)
Тут мы сказали сети тренироваться 30 эпох, брать данные из training_data, размер
одной выборки (mini-batch'a) - 10 и шаг градиентного спуска равен 3.0.
"""
class Network(object):
    def __init__(self, sizes):
        """
        sizes - список из значений, где i-ое значение описывает i-ый слой в нашей сети,
        а точнее количество нейронов в i-ом слое
        """
        self.num_layers = len(sizes)
        self.sizes = sizes

        # Генерируем рандомные баесы для каждого нейрона на y-ом слое
        # Другими словами в self.biases будет список, каждый элемент которого будет
        # np.array'ем, хранящим в себе баесы для каждого нейрона на этом слое
        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]

        # Генерируем рандомные веса для каждого нейрона на y-ом слое:
        # проходим по парам смежных слоев (сначала берем 1 и 2, потом 2 и 3 и т.д.) и
        # для каждого нейрона y-го слоя генерируем sizes[y-1] весов. То есть получается
        # список из np.array'ев, где каждый np.array описывает веса нейронов для конкретного
        # слоя и содержит двумерный массив (массив массивов, где каждый вложенный массив
        # содержим веса для нейрона)
        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]

    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):
        """
        Тренируем нейросеть, используя стохастический градиентный спуск (т.е.
        разбиваем датасет на выборки (mini batches), затем тренируем сеть по
        каждой такой выборке отдельно).
        Если передан параметр test_data, тогда сеть будет проводить оценку
        обучения каждую эпоху, текущий прогресс будет выводиться в консоль.
        Это полезно для просмотра прогресса.
        training_data - список картежей (x, y) представляющий тренировочные
          входные данные и желаемые выодные данные
        epochs - количество эпох тренировки
        mini_batch_size - размер батча
        eta - норма обучения (шаг градиентного спуска, обычно обозначается как ƞ)
        """

        # Конвертация <class 'zip'> -> <class 'list'> для совместимости с Python3
        training_data = list(training_data)
        test_data = list(test_data)

        if test_data:
            n_test = len(test_data)
        n = len(training_data)

        # Повторяем обучение по нашему датасету столько раз, сколько
        # было задано в аргументе количества эпох обучения
        for j in range(epochs):
            # Перемешиваем элементы данных в датасете
            random.shuffle(training_data)

            # Разбиваем датасет training_data на список из выборок (каждая
            # будет иметь mini_batch_size элементов из датасета)
            mini_batches = [
                training_data[k:k+mini_batch_size]
                for k in range(0, n, mini_batch_size)
            ]

            # По каждой выборке обучаем сеть (а не по всему датасету, т.к. у нас
            # используется стохастический градиентный спуск)
            for mini_batch in mini_batches:
                self.update_mini_batch(mini_batch, eta)

            # Просто выводим информацию о прогрессе (для удобства наблюдения и
            # отладки)
            if test_data:
                # Выводим информацию о номере эпохи, количестве правильных ответов
                # нейросети по тестовой выборке и размер тестовой выборки
                print('Epoch {}: {} / {}'.format(j, self.evaluate(test_data), n_test))
            else:
                print('Epoch {} complete'.format(j))

    def update_mini_batch(self, mini_batch, eta):
        """
        Изменяем/корректируем веса и баесы, применяя градиентный спуск,
        использую обратное распространение (backpropagation) к текущей
        выборке (mini batch).
        mini_batch - список кортежей вида (x, y)
        eta - градиентный шаг (ƞ)
        """

        # Тут будут храниться значения градиента для всех весов и баесов (разбитые по слоям)
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]

        # Размер выборки (мини-батча), нужен для подсчета среднего арифметического
        # градиента для этой выборки
        mini_batch_size = len(mini_batch)

        # Вычисляем градиент для весов и баесов (в текущей выборке)
        for x, y in mini_batch:
            # Вычисляем градиент для текущего экземпляра данных (картинки)
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            # Суммируем значения градиента (чтобы потом найти среднее арифметическое, т.е.
            # умножить сумму на 1/mini_batch_size)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]

        # Апдейтим веса с помощью среднего градиента по формуле: w = w - ƞ * (Σ∇W / n), где
        # w - текущее значение веса, ƞ - градиентный шаг,
        # n - количество элементов в выборке (батче),
        # Σ∇W - сумма градиентов для весов текущей выборки => (Σ∇W / n) - средний градиент
        # для этой выборки
        self.weights = [
            w-(eta/mini_batch_size)*nw for w, nw in zip(self.weights, nabla_w)
        ]
        # Аналогично апдейтим баесы (см. комментарий выше)
        self.biases = [
            b-(eta/mini_batch_size)*nb for b, nb in zip(self.biases, nabla_b)
        ]

    def backprop(self, x, y):
        """
        Функция возвращает картеж (nabla_b, nabla_w) (∇B и ∇W для баесов и весов
        соответственно), представляющий градиент для cost-функции Cₓ.
        nabla_b и nabla_w - списки, где каждый элемент - это numpy массив,
        представляющий собой набор значений градиента для каждого слоя сети
        (подобно self.biases и self.weights.
        x - входные значения (в нашем случае пиксели изображения)
        y - выходные эталонные значения
        """

        # Создаем списки с обнуленными масивами значений градиента
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]

        # Входные значения (пикселей) являются "активациями" для первого
        # слоя нейронов
        activation = x
        # Список для хранения всех активаций (слой за слоем)
        activations = [x]
        # Список для хранения всех z векторов (слой за слоем)
        # Вектор z хранит в себе суммы входных значений, умноженных на веса и с
        # прибавленным баесом
        zs = []

        # Распространение активаций от входного слоя до выходного:
        # высчитываем сумму входных значений (умноженных на веса и с
        # прибавленным баесом) и значений активаций для каждого слоя
        for b, w in zip(self.biases, self.weights):
            # Высчитываем вектор сумм z для текущего слоя. Тут w - вектор ве
            z = np.dot(w, activation) + b
            # Добавляем в список веткоров сумм
            zs.append(z)
            # Высчитываем вектор активаций для текущего слоя
            activation = sigmoid(z)
            # Добавляем в список активаций
            activations.append(activation)

        # Обратное распространение.
        # Обозначим номер текущего слоя (в нашем случае последнего) - l, а номер предыдущего
        # текущему слоя: l-1 (в нашем случае предпоследний слой). Нейроны текущего l-го слоя
        # обозначим c индексами от 0 до j (т.е. aⱼ - значение активации j-го нейрона l-го слоя),
        # а нейроны слоя l-1 обозначим индексами от 0 до k). Вес, соединяющий k-ый нейрон с
        # j-ым, будем обозначать wⱼₖ.

        # activations[-1] - вектор активаций последнего слоя (значения выходных нейронов)
        # zs[-1] - вектор сумм входных значений, умноженных на веса с прибавленным баесом
        #   последнего слоя (значения, которые были аргументами сигмоиды на последнем слое)
        # self.cost_derivative(activations[-1], y) - врзвращает вектор частных производных
        #   cost-функции по daₗ (где aₗ - вектор значений активации l-го слоя (последнего))
        # sigmoid_prime(zs[-1]) - возвращает вектор производных функции активации по dz
        # delta - вектор производных cost-функции по dbⱼ (баесу j-uj нейрона l-го слоя), т.е.
        #   delta - вектор из элементов:
        #   dCₓ/dbⱼ = dCₓ/daⱼ * daⱼ/dzⱼ * dzⱼ/dbⱼ = dCₓ/daⱼ * daⱼ/dzⱼ, т.к. zⱼ = Σ(wⱼₖ*aₖ) + bⱼ,
        #   то dzⱼ/dbⱼ = 1, где Σ(wⱼₖ*aₖ) - сумма активаций (l-1)-го слоя, умноженных на веса
        #   l-го слоя для j-го нейрона, bⱼ - баес для l-го слоя (т.е. для любого j-го нейрона).
        #   Другими словами, delta - вектор производных cost-функции по баесам слоев (или насколько
        #   сильно изменение определенного баеса повлияет на изменение значения cost-функции)
        # Т.к. daⱼ/dzⱼ = σ'(zⱼ) - производная сигмодиды по zⱼ, то каждый элемент вектора delta
        # будет высчитываться по формуле: (aⱼ-yⱼ)*σ'(zⱼ), где yⱼ - эталонное значение для j-го
        # нейрона l-го слоя. Чтобы посчитать целый вектор delta, достаточно вместо каждого значения
        # нейрона l-го слоя подставить вектора значений l-го слоя: delta = (aₗ-y)*σ'(zₗ)
        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])

        # Вспомним, что градиент для весов j-го нейрона l-го слоя вычисляется по формуле:
        # dCₓ/dwⱼₖ = dCₓ/daⱼ * daⱼ/dzⱼ * dzⱼ/dwⱼₖ (по правилу вычисления производных сложной функции)
        # dCₓ/daⱼ = aⱼ - yⱼ (т.к. Сₓ = 1/2*(a-y)²)
        # daⱼ/dzⱼ = σ'(zⱼ) - производная сигмодиды по zⱼ
        # dzⱼ/dwⱼₖ = aₖ, где aₖ - значение активации (l-1)-го слоя
        # А градиент для баеса j-го нейрона l-го слоя:
        # dCₓ/dbⱼ = dCₓ/daⱼ * daⱼ/dzⱼ * dzⱼ/dbⱼ = dCₓ/daⱼ * daⱼ/dzⱼ (т.к. dzⱼ/dbⱼ = 1) =>
        # => dCₓ/dbⱼ = deltaⱼ, где deltaⱼ - элемент вектора delta для j-го нейрона
        nabla_b[-1] = delta

        # И так как каждый элемент delta равен dCₓ/daⱼ * daⱼ/dzⱼ,
        # то каждый элемент вектора значений градиента для весов l-го слоя вычисляется
        # по формуле: dCₓ/dwⱼ = deltaⱼ * aₖ
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())

        # Note that the variable l in the loop below is used a little
        # differently to the notation in Chapter 2 of the book.  Here,
        # l = 1 means the last layer of neurons, l = 2 is the
        # second-last layer, and so on.  It's a renumbering of the
        # scheme in the book, used here to take advantage of the fact
        # that Python can use negative indices in lists.
        # Начинаем с предпоследнего ((l-1)-го) слоя и до первого (для последнего
        # значения градиента уже посчитали выше)
        for l in range(2, self.num_layers):
            # Достаем вектор zₗ₋₁ текущего (l-1)-го слоя
            z = zs[-l]

            # Считаем веткор производных функции активации по аргументу zₗ₋₁, т.е каждый элемент
            # будет считаться по формуле: daₖ/dzₖ = σ'(zₖ) или daₗ₋₁/dzₗ₋₁ = σ'(zₗ₋₁) (для целого слоя).
            # Где aₖ - значение активации k-го нейрона (l-1)-го слоя, zₖ - сумма входных значений,
            # умноженных на веса с прибавленным баесом для k-го нейрона (l-1)-го слоя
            sp = sigmoid_prime(z)

            # Вспомним, что aₖ - значение активации k-го нейрона (l-1)-го слоя. Оно оказывает влияние
            # на j нейронов следующего (l-го) слоя, поэтому значения градиента для баесов (вектора delta)
            # и весов каждого слоя, кроме выходного будут считаться по другой формуле.
            # aₖ влияет на zⱼ, zⱼ - на aⱼ, aⱼ - на Cₓ.
            # Поэтому dCₓ/daₖ будет равняться сумме производных:
            # dCₓ/daₖ = Σ(dCₓ/daⱼ * daⱼ/dzⱼ * dzⱼ/daₖ) c j=0 по j=k-1. При этом dzⱼ/daₖ = wⱼₖ(вес j нейрона
            # следующего (l-го), связанного с k-ым нейроном текущего (l-го) слоя), и dCₓ/daⱼ * daⱼ/dzⱼ - это
            # элементы вектора delta слоя l, то есть dCₓ/daₖ = Σ(deltaⱼ * wⱼₖ) c j=0 по j=k-1, где deltaⱼ -
            # j-ый элемент вектора значений градиента для баеса слоя l.
            # self.weights[-l+1] - np.array весов для нейронов l-го слоя размерности (j, k), где j - это
            # количество нейронов на l-ом слое, а k - кол-во нейронов на (l-1)-ом слое.
            # delta - np.array (или вектор) размерности (j, 1).
            # Тогда транспонировав self.weights[-l+1] их можно перемножить, как матрицы, получив в результате
            # вектор размерности (k, 1), который и будет являться вектором значений дифференциала dCₓ/daₖ
            # (l-1)-го слоя (убедиться можно в этом просто посмотрев на формулу умножения матрицы на вектор-
            # столбец). После остается только умножить этот вектор на вектор значений дифференциала daₖ/dzₖ =
            # = σ'(zₖ), то есть на вектор σ'(zₗ₋₁).
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp

            # Сохраняем значения градиента для баеса (l-1)-ого слоя
            nabla_b[-l] = delta

            # Сохраняем значения градиента для весов (l-1)-ого слоя
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
            
        return (nabla_b, nabla_w)

    def feedforward(self, a):
        """
        Вызывается только, когда метод SGD вызван с аргументом `test_data`. То
        есть нужна для эксплуатации уже натренированной нейросети (чтобы просто
        получить выходные данные о том, какую цифру распознала сеть).
        """
        # Распространяем значения активации от входного слоя до выходного.
        # Переменная a - вектор из значений активации предыдущего слоя (для первого
        # это будут просто вектор входных данных).
        # Для каджого слоя сети высчитываем вектор значений активации всех нейронов
        for b, w in zip(self.biases, self.weights):
            # Так как мы каждый раз апдейтим `a` (вектор значений активаций), то при
            # итерации по слоям сети, он автоматически будет подаваться обновленным
            # для следующего слоя
            a = sigmoid(np.dot(w, a) + b)

        return a

    def evaluate(self, test_data):
        """
        Возвращает число тестовых экземпляров данных, для которых
        нейросеть выдала корректный результат (не ошиблась).
        """
        # В test_results сохраняем пары значений-векторов: вектор значений выходных
        # данных (активаций выходного слоя сети) и вектор эталонных значений (как
        # нужно было бы ответить)
        test_results = [
            (np.argmax(self.feedforward(x)), y)
            for (x, y) in test_data
        ]

        # Возвращаем сумму правильных (безошибочных) ответов нейросети
        return sum(int(x == y) for (x, y) in test_results)

    def cost_derivative(self, output_activations, y):
        """
        Функция возвращает частную производную cost-функции Сₓ
        по da (a - вектор активаций выходного слоя или output_activations,
        y - вектор эталонных значений.
        Функция активации высчитывается по формуле:
        Сₓ = 1/2*(a-y)²
        Тогда производная dСₓ/da = 1/2*2*(a-y) = a-y
        """
        return (output_activations-y)